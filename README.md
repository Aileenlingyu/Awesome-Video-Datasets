# Awesome-Video-Datasets

## Action Recognition

* **[UCF101](https://www.crcv.ucf.edu/papers/UCF101_CRCV-TR-12-01.pdf)**: A Dataset of 101 Human Actions Classes From Videos in The Wild [Homepage](https://www.crcv.ucf.edu/data/UCF101.php)
* **[ActivityNet](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Heilbron_ActivityNet_A_Large-Scale_2015_CVPR_paper.pdf)**: A Large-Scale Video Benchmark for Human Activity Understanding (CVPR 2015)[Homepage](http://activity-net.org/index.html)
* **Kinetics**: [Kinetics-400](https://arxiv.org/abs/1705.06950) [Kinetics-600](https://arxiv.org/abs/1808.01340) [Kinetics-700](https://arxiv.org/abs/1907.06987) [Homepage](https://deepmind.com/research/open-source/kinetics)
* **[AVA](https://arxiv.org/abs/1705.08421)**: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions [Homepage](http://research.google.com/ava/)
* **[EPIC-KITCHENS](https://openaccess.thecvf.com/content_ECCV_2018/papers/Dima_Damen_Scaling_Egocentric_Vision_ECCV_2018_paper.pdf)**: Scaling Egocentric Vision: The EPIC-KITCHENS Dataset [Homepage](https://epic-kitchens.github.io/2021)
* **HOMAGE**: Home Action Genome: Cooperative Compositional Action Understanding (CVPR 2021) [Homepage](https://homeactiongenome.org/)</br> 
27 participants, 12 sensor types, 75 activities, 453 atomic actions, 1,752 synchronized sequences, 86 object classes, 29 relationship classes, 497,534 bounding boxes, 583,481 relationships. 

* **[MMAct](https://openaccess.thecvf.com/content_ICCV_2019/papers/Kong_MMAct_A_Large-Scale_Dataset_for_Cross_Modal_Human_Action_Understanding_ICCV_2019_paper.pdf)**: A Large-Scale Dataset for Cross Modal Human Action Understanding (ICCV 2019) [Homepage](https://mmact19.github.io/2019/)
* **[LEMMA](https://arxiv.org/pdf/2007.15781.pdf)**: A Multi-view Dataset for LEarning Multi-agent Multi-task Activities (ECCV 2020) [Homepage](https://sites.google.com/view/lemma-activity)
* **[Action Genome](https://arxiv.org/pdf/1912.06992.pdf)**: Actions as Compositions of Spatio-temporal Scene Graphs (CVPR 2020) [Homepage](https://www.actiongenome.org/)
* **[TITAN](https://openaccess.thecvf.com/content_CVPR_2020/papers/Malla_TITAN_Future_Forecast_Using_Action_Priors_CVPR_2020_paper.pdf)**: Future Forecast using Action Priors (CVPR 2020) [Homepage](https://usa.honda-ri.com/titan)
* **[PKU-MMD](https://arxiv.org/abs/1703.07475)**: A Large Scale Benchmark for Continuous Multi-Modal Human Action Understanding (ACM Multimedia Workshop) [Homepage](https://github.com/ECHO960/PKU-MMD#pku-mmd-a-large-scale-benchmark-for-continuous-multi-modal-human-action-understanding)



## Action/Event Localization
* [EEV](https://github.com/google-research-datasets/eev) (EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video, 2020)
* Multi-shot Temporal Event Localization: a Benchmark (CVPR 2021)
